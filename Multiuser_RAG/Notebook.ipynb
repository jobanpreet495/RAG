{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cda8efc-584c-4e64-b76c-362cd7301441",
   "metadata": {},
   "source": [
    "## Multiuser RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d75590b5-0e97-4967-bbfb-9aa7f97840d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7f6b7f-b60b-4b78-9410-b05563c297bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser \n",
    "from langchain_core.prompts import  ChatPromptTemplate ,MessagesPlaceholder\n",
    "from langchain.memory import FileChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from pathlib import Path\n",
    "\n",
    "model = ChatOpenAI(temperature = 0 , model =\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa2824d-0efc-4221-8339-297f010f6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1cf1805-0f4f-4fd6-9139-b68321b2e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dir= Path(\"./message_history\")\n",
    "history_dir.mkdir(parents  = True , exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad47cc75-9345-4768-ad16-f6f354a6053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id:str) -> FileChatMessageHistory:\n",
    "    session_history_path = history_dir / f\"{session_id}.json\"\n",
    "    return FileChatMessageHistory(str(session_history_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767456e2-380a-4356-b3cc-238322324082",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_chain = RunnableWithMessageHistory(\n",
    "    chain , get_session_history ,  input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6408d47-6bdc-466e-bf64-e5d95aa37cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is AI\"\n",
    "session_id = \"user001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41db611-1ae4-4f5a-b616-0a12fcda7a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 9956faa5-445b-441e-a305-dd9181fcbf31 not found for run f58e1d40-ecde-46f1-bc64-d5d0dfdbea28. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI, or artificial intelligence, refers to the simulation of human intelligence processes by machines, such as learning, reasoning, and self-correction.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_chain.invoke({'input':query},\n",
    "                 {'configurable':{'session_id':session_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44201b77-f211-46f3-9c1e-6a156a7b65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 90133505-db62-4f9a-8884-6697d7404812 not found for run 5241f635-9da5-4d82-9a84-dc761d1e5dce. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"What is AI?\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_chain.invoke({'input':\"what is my previous question ?\"},\n",
    "                 {'configurable':{'session_id':session_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a74cdb-a14d-494a-80ac-4f25330c026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 798db8b0-36d4-42d3-981e-972f0241e123 not found for run 73489b27-44db-4db0-8d4c-55ec8deeabe0. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI involves the simulation of human intelligence processes by machines, while rule-based systems rely on predefined rules and logic to make decisions or perform tasks.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_chain.invoke({'input':\"How it is different than Rule  based system ?\"},\n",
    "                 {'configurable':{'session_id':session_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68ff2e-d746-48ba-a4e2-15b2c2e54dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92dd2747-64b2-4bf9-8da2-772e21aa5006",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73e530e2-e6ae-4ff2-9cc0-f6096c32b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import  FAISS\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.output_parser import StrOutputParser \n",
    "from langchain.memory import FileChatMessageHistory\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9f4f7-5fc1-4794-b16f-27564540c3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0249c593-5770-4a29-825d-4ee92d48247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading already created index\n",
    "vectorstore=FAISS.load_local(\"index\" , embeddings=OpenAIEmbeddings() ,  allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f74c08a-bd3a-4027-86b5-1fddc53ae255",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "\n",
    "### Answer question ###\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "708ce636-a3ce-4ffd-a578-60b109a64d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dir= Path(\"./message_history\")\n",
    "history_dir.mkdir(parents  = True , exist_ok=True)\n",
    "\n",
    "def get_session_history(session_id:str) -> FileChatMessageHistory:\n",
    "    session_history_path = history_dir / f\"{session_id}.json\"\n",
    "    return FileChatMessageHistory(str(session_history_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "927902a6-1279-4ec4-9769-9b2eaedf3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98d85b49-5ea5-4fff-bbbd-33792280f864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 8ed2bd47-1767-4094-8a22-0eaebc7cb3d4 not found for run 046749b3-4b73-4ed2-b488-15d47fe32d39. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Machine learning is a transformative branch of artificial intelligence that empowers computers to learn from and make decisions based on data. Unlike traditional programming, where explicit instructions dictate the outcome, ML algorithms identify patterns and infer rules directly from the data they process, improving their performance with experience over time.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is machine learning ?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"user001\"}\n",
    "    },  \n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d66c4255-f9b6-4c09-883b-c5ae5be788fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run d44a50cf-450b-49ea-a218-344d3791af13 not found for run bba275aa-9ae9-4051-b0f0-813df9245dab. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"What is machine learning?\"'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is my previous question ?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"user001\"}\n",
    "    },  \n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77a9e55a-36f6-44c0-af1c-bc923e5139e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run b677d705-2158-46d5-8ea0-86312d64c479 not found for run 19194a3e-4d34-40c1-97b6-4e736379b94f. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning that uses neural networks with many layers to model complex patterns in large datasets.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"How it is different than deep learning. Give answer in one line.\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"user001\"}\n",
    "    },  \n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0f94115-66b8-44d7-ace5-202cd2258d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run ba4e8e8f-47a2-4acf-a272-2d9a7f8be1df not found for run 6cd7cffa-0ddf-4ab5-8750-ce66447ecf94. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Supervised learning involves training models on labeled data to make predictions or classifications. It includes techniques like regression for continuous outcomes and classification for discrete categories. Common algorithms in supervised learning include linear regression, decision trees, random forests, support vector machines, and neural networks.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"what  is supervised learning\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"user002\"}\n",
    "    },  \n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2b08c91-b498-4e47-9c0b-df9a56dcd0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run af4c03f6-0e7c-4a80-9f26-d340a234c0ef not found for run 04a82388-32d4-4939-b2db-4897da32b2ca. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previously asked question was about supervised learning, which involves training models on labeled data to make predictions or classifications. It includes techniques like regression for continuous outcomes and classification for discrete categories. Common algorithms in supervised learning include linear regression, decision trees, random forests, support vector machines, and neural networks.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"what is my previously asked question ?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"user002\"}\n",
    "    },  \n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab8a0c77-c8d1-4c4a-abc5-6b36078a4899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run ca19a72b-51e5-445d-911c-f6b1eb3c1c9a not found for run c263e5a3-07b9-4243-8597-4e3a7c21e6d6. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"How it is different than deep learning. Give answer in one line.\"'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"what is my previously asked question ?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"user001\"}\n",
    "    },  \n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f78972-2c0b-4355-9e9d-99c929520dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045ec84e-5868-4400-a70c-847e5fd1977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo[srv] in /home/erginous/anaconda3/envs/RAG/lib/python3.10/site-packages (4.7.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/erginous/anaconda3/envs/RAG/lib/python3.10/site-packages (from pymongo[srv]) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install \"pymongo[srv]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33539ddb-e52a-4c78-b66b-3b06cb64e7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be1ab11a-7b89-4d6f-b10a-61f1a4af3c93",
   "metadata": {},
   "source": [
    "## Storing chat history /user/session_id in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ae5388-b4b7-4bdd-bf65-547f0b377e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U --quiet langchain-mongodb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa9af1-91f9-47e9-b3e3-c44c0922b0dc",
   "metadata": {},
   "source": [
    "###### Below code reference from LangChain --> https://python.langchain.com/v0.2/docs/integrations/memory/mongodb_chat_message_history/\n",
    "\n",
    "* Lets firstly understand how MongoDBChatMessageHistory works , then we will switch to out actual code of connecting with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68155949-878d-4345-aec3-95c9c877825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory\n",
    "\n",
    "chat_message_history = MongoDBChatMessageHistory(\n",
    "    session_id=\"test_session\",\n",
    "    connection_string=\"mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.2.9\",\n",
    "    database_name=\"chatbot\",\n",
    "    collection_name=\"chat_histories\",\n",
    ")\n",
    "\n",
    "chat_message_history.add_user_message(\"Hello\")\n",
    "chat_message_history.add_ai_message(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01bdf588-7ef0-4dc8-b636-0d7b6fb30525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello'), AIMessage(content='Hi')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_message_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "373157d7-1e48-4b1c-8fa8-5ad57a797aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "897e8f9a-17da-4a8b-8020-1a9bd9a26a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "131953a6-2e30-4888-8b53-49208e22698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "202aa77c-bdfd-45a3-b3fb-7d04ce1c597d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['history', 'question'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ae051f7-3bb7-4d0e-ad6e-9beacccd252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: MongoDBChatMessageHistory(\n",
    "        session_id=session_id,\n",
    "        connection_string=\"mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.2.9\",\n",
    "        database_name=\"chatbot\",\n",
    "        collection_name=\"chat_histories\",\n",
    "    ),\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78e12996-c00b-4df0-bbb7-f96e2d6e329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we configure the session id\n",
    "config = {\"configurable\": {\"session_id\": \"user1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6d19c4d-ff75-4588-b54c-809c255eb0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run ac2e354d-5919-43ed-bd06-a8b64df211f2 not found for run daa229ea-1daf-470c-b2d3-765c629fe09e. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Jobanpreet! It's nice to meet you. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 25, 'total_tokens': 45}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f03f1137-c6ad-4601-8eea-d164da460fb8-0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke({\"question\": \"Hi! I'm Jobanpreet\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8210a82-54a5-4561-9a95-60392004a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run f04f0c6e-c5ac-4129-a4d5-0192d883924a not found for run 1230d347-8581-4310-930b-5b5dcacbcde6. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Jobanpreet. How can I assist you further?', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 56, 'total_tokens': 71}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6201ba6b-3341-4c9f-96ec-b926ddbe49ae-0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke({\"question\": \"Whats my name\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd156ef0-0b8a-4424-a268-2210002e4dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run f76c9e91-7d65-4d07-b502-621377d26e49 not found for run cbd41d6e-8504-43f1-9f99-56aadbfe883a. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I don't have access to personal information like your name unless you provide it to me. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 20, 'total_tokens': 49}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9da5c3e7-699e-4ab1-9279-6f1ada92c897-0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where we configure the session id\n",
    "config = {\"configurable\": {\"session_id\": \"user2\"}}\n",
    "chain_with_history.invoke({\"question\": \"Whats my name\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c352c353-3a85-421b-b891-716333e9f287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run f7a9d05f-68cf-400e-800f-f72564eb285b not found for run ba2a2805-dc65-4883-b36b-6355048d18fe. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I apologize for misunderstanding your previous question. Your previous question was \"What\\'s my name?\" How can I assist you further?', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 64, 'total_tokens': 89}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-fd933a9d-1165-4e5e-af77-fca86a2d50a9-0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where we configure the session id\n",
    "\n",
    "chain_with_history.invoke({\"question\": \"Whats my is my previous question ?\"}, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe81ad-bce0-4532-ac0f-69ab40355242",
   "metadata": {},
   "source": [
    "#### Now lets use RAG , MongoDBChatMessageHistory for saving messages to Mongodb instead of json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e081c39-2ed8-47b5-a4fc-7c537f71654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import  FAISS\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.output_parser import StrOutputParser \n",
    "from langchain.memory import FileChatMessageHistory\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b09cfab-a382-469c-91fb-f8ffd698440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading already created index\n",
    "vectorstore=FAISS.load_local(\"index\" , embeddings=OpenAIEmbeddings() ,  allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4499803e-6a4e-4038-b92c-68d75442a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt \n",
    ")\n",
    "\n",
    "\n",
    "### Answer question ###\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "069395fb-2de5-4487-a36e-e4f72833d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    lambda session_id: MongoDBChatMessageHistory(\n",
    "        session_id=session_id,\n",
    "        connection_string=\"mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.2.9\",\n",
    "        database_name=\"chatbot\",\n",
    "        collection_name=\"chat_histories\",\n",
    "    ),\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caf3ab37-f9ca-4553-b824-10b457eca565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 243174e8-b45b-4842-ade3-d4ad40fc91f6 not found for run 08b028bf-682a-4c4e-9288-c01a414a745a. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Machine learning is a transformative branch of artificial intelligence that empowers computers to learn from and make decisions based on data. Unlike traditional programming, where explicit instructions dictate the outcome, ML algorithms identify patterns and infer rules directly from the data they process, improving their performance with experience over time.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where we configure the session id\n",
    "config = {\"configurable\": {\"session_id\": \"user001\"}}\n",
    "chain_with_history.invoke({\"input\": \"What is Machine learning ?\"}, config=config)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b75ed1ae-60b9-4206-9c06-9b91b9375ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 8118a874-20be-4b9a-a9b2-25ead71e9c88 not found for run aadaa799-d076-47cc-89fc-edf052cde6fe. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Supervised Learning?',\n",
       " 'chat_history': [HumanMessage(content='What are types of Linear Regression  ?'),\n",
       "  AIMessage(content='Linear regression is a supervised learning technique used for predicting continuous outcomes. There are two main types of linear regression: simple linear regression, which involves one independent variable, and multiple linear regression, which involves multiple independent variables. Simple linear regression is used when there is a linear relationship between the dependent and independent variables, while multiple linear regression can handle more complex relationships by incorporating multiple predictors.'),\n",
       "  HumanMessage(content='What are types of Linear Regression  ?'),\n",
       "  AIMessage(content='Linear regression is a supervised learning technique used for predicting continuous outcomes. There are two main types of linear regression: simple linear regression, which involves one independent variable, and multiple linear regression, which involves multiple independent variables. Simple linear regression is used when there is a linear relationship between the dependent and independent variables, while multiple linear regression can handle more complex relationships by incorporating multiple predictors.'),\n",
       "  HumanMessage(content='Why we are squaring the errors ?'),\n",
       "  AIMessage(content=\"Squaring the errors in regression models serves multiple purposes. It penalizes larger errors more than smaller ones, emphasizing the impact of outliers on the model's performance. Additionally, squaring the errors ensures that the optimization process (e.g., in least squares regression) results in a unique solution by making the objective function convex. This helps in finding the best-fitting line or curve that minimizes the overall error across the dataset.\"),\n",
       "  HumanMessage(content='What is Machine learning ?'),\n",
       "  AIMessage(content='Machine learning is a transformative branch of artificial intelligence that enables computers to learn from data and make decisions without being explicitly programmed. ML algorithms identify patterns and infer rules directly from the data they process, improving their performance with experience over time. This capability is grounded in various learning paradigms such as supervised learning, unsupervised learning, and reinforcement learning.'),\n",
       "  HumanMessage(content='What is Machine learning ?'),\n",
       "  AIMessage(content='Machine learning is a transformative branch of artificial intelligence that empowers computers to learn from and make decisions based on data. Unlike traditional programming, where explicit instructions dictate the outcome, ML algorithms identify patterns and infer rules directly from the data they process, improving their performance with experience over time.')],\n",
       " 'context': [Document(page_content='Supervised learning includes techniques like regression and classification. In regression tasks, the model predicts continuous outcomes, such as predicting house prices based on features like size and location. In classification tasks, the model assigns inputs to discrete categories, such as diagnosing a disease based on patient data. Common algorithms in supervised learning include linear regression, decision trees, random forests, support vector machines, and neural networks.', metadata={'source': 'data.txt'}),\n",
       "  Document(page_content='Machine learning (ML) is a transformative branch of artificial intelligence (AI) that empowers computers to learn from and make decisions based on data. Unlike traditional programming, where explicit instructions dictate the outcome, ML algorithms identify patterns and infer rules directly from the data they process, improving their performance with experience over time. This capability is grounded in various learning paradigms such as supervised learning, where models are trained on labeled data; unsupervised learning, which involves drawing inferences from unlabeled datasets; and reinforcement learning, where agents learn by interacting with their environment to maximize some notion of cumulative reward.', metadata={'source': 'data.txt'}),\n",
       "  Document(page_content='Unsupervised learning, on the other hand, is used to uncover hidden patterns or intrinsic structures in data without pre-existing labels. Clustering algorithms, such as k-means, hierarchical clustering, and DBSCAN, group similar data points together. Dimensionality reduction techniques like Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE) reduce the number of features in a dataset while preserving its important characteristics, making it easier to visualize or process.', metadata={'source': 'data.txt'}),\n",
       "  Document(page_content='In conclusion, machine learning represents a paradigm shift in how we harness computational power to analyze data and make informed decisions. Its applications are vast and transformative, touching nearly every aspect of modern life. As the field continues to evolve, it will undoubtedly unlock new potentials, fostering advancements that were once the realm of science fiction. However, the journey ahead requires careful navigation of technical, ethical, and societal challenges to fully realize the potential of this groundbreaking technology.', metadata={'source': 'data.txt'})],\n",
       " 'answer': 'Supervised learning is a machine learning paradigm where models are trained on labeled data, meaning the input data is paired with the correct output. This type of learning involves predicting or classifying data based on known examples, such as predicting house prices or diagnosing diseases. Common algorithms in supervised learning include linear regression, decision trees, random forests, support vector machines, and neural networks.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke({\"input\": \"What is Supervised Learning?\"}, config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
